{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the Dataset\n",
    "DATA_DIR = \"Dataset/trainingSet/\"\n",
    "with open('Dataset/Processed/MNIST_Dataset.csv', 'wb') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"filename\", \"label\"])\n",
    "    for label in xrange(0, 9):\n",
    "        path = os.path.join(DATA_DIR, str(label))\n",
    "        for p in os.listdir(path):\n",
    "            filename = os.path.join(path, p)\n",
    "            writer.writerow([filename, str(label)])\n",
    "            \n",
    "data = pd.read_csv(\"Dataset/Processed/MNIST_Dataset.csv\")\n",
    "data = data.iloc[np.random.permutation(len(data))]\n",
    "train, validation = data[:25000],data[25000:]\n",
    "train.to_csv(\"Dataset/Processed/MNIST_Train.csv\", index=False)\n",
    "validation.to_csv(\"Dataset/Processed/MNIST_Validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import MNISTDataset\n",
    "mnist_train_dataset = MNISTDataset(csv_file='./Dataset/Processed/MNIST_Train.csv', root_dir='./')\n",
    "mnist_val_dataset = MNISTDataset(csv_file='./Dataset/Processed/MNIST_Validation.csv', root_dir='./')\n",
    "train_dataloader = DataLoader(mnist_train_dataset, batch_size=1000, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(mnist_val_dataset, batch_size=1000, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 25, 11, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.2030 -2.4003 -2.2637  ...  -2.2453 -2.3496 -2.3419\n",
       "-2.1135 -2.3235 -2.3174  ...  -2.2239 -2.4350 -2.3602\n",
       "-2.1792 -2.3416 -2.2618  ...  -2.2791 -2.3211 -2.3834\n",
       "          ...             â‹±             ...          \n",
       "-2.2851 -2.3482 -2.1658  ...  -2.2748 -2.3157 -2.3222\n",
       "-2.1670 -2.3555 -2.2609  ...  -2.2491 -2.3827 -2.3988\n",
       "-2.1718 -2.3143 -2.2409  ...  -2.2462 -2.3561 -2.3432\n",
       "[torch.FloatTensor of size 100x10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import Net \n",
    "model_instance = Net()\n",
    "v = Variable(torch.randn(100,1,28,28))\n",
    "model_instance.forward(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model_instance.parameters(), lr=0.00001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "        data, target = Variable(data[\"image\"]), Variable(data[\"label\"])\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(data.float())\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        if batch_idx % 1 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
    "                100. * batch_idx / len(train_dataloader), loss.data[0]))\n",
    "    print('Train accuracy : {:.6f}'.format(100. * correct / len(train_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data in val_dataloader:\n",
    "        data, target = Variable(data[\"image\"], volatile=True), Variable(data[\"label\"])\n",
    "        output = model(data.float())\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(val_dataloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_dataloader.dataset),\n",
    "        100. * correct / len(val_dataloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [0/24999 (0%)]\tLoss: 0.270428\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [1000/24999 (4%)]\tLoss: 0.281985\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [2000/24999 (8%)]\tLoss: 0.278986\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [3000/24999 (12%)]\tLoss: 0.292941\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [4000/24999 (16%)]\tLoss: 0.302977\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [5000/24999 (20%)]\tLoss: 0.283868\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [6000/24999 (24%)]\tLoss: 0.294156\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [7000/24999 (28%)]\tLoss: 0.274148\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [8000/24999 (32%)]\tLoss: 0.285527\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [9000/24999 (36%)]\tLoss: 0.293281\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [10000/24999 (40%)]\tLoss: 0.274014\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [11000/24999 (44%)]\tLoss: 0.293062\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [12000/24999 (48%)]\tLoss: 0.304710\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [13000/24999 (52%)]\tLoss: 0.312356\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [14000/24999 (56%)]\tLoss: 0.326609\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [15000/24999 (60%)]\tLoss: 0.233912\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [16000/24999 (64%)]\tLoss: 0.319808\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [17000/24999 (68%)]\tLoss: 0.294187\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [18000/24999 (72%)]\tLoss: 0.278472\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [19000/24999 (76%)]\tLoss: 0.266984\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [20000/24999 (80%)]\tLoss: 0.336973\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [21000/24999 (84%)]\tLoss: 0.294395\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [22000/24999 (88%)]\tLoss: 0.307035\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 1 [23000/24999 (92%)]\tLoss: 0.277780\n",
      "torch.Size([999, 25, 11, 11])\n",
      "Train Epoch: 1 [23976/24999 (96%)]\tLoss: 0.326366\n",
      "Train accuracy : 91.203648\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([811, 25, 11, 11])\n",
      "\n",
      "Test set: Average loss: 0.1555, Accuracy: 12203/12811 (95%)\n",
      "\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [0/24999 (0%)]\tLoss: 0.265933\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [1000/24999 (4%)]\tLoss: 0.258425\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [2000/24999 (8%)]\tLoss: 0.331190\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [3000/24999 (12%)]\tLoss: 0.272191\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [4000/24999 (16%)]\tLoss: 0.313084\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [5000/24999 (20%)]\tLoss: 0.293010\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [6000/24999 (24%)]\tLoss: 0.248237\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [7000/24999 (28%)]\tLoss: 0.286853\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [8000/24999 (32%)]\tLoss: 0.347401\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [9000/24999 (36%)]\tLoss: 0.260537\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [10000/24999 (40%)]\tLoss: 0.260067\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [11000/24999 (44%)]\tLoss: 0.284468\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [12000/24999 (48%)]\tLoss: 0.314205\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [13000/24999 (52%)]\tLoss: 0.332930\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [14000/24999 (56%)]\tLoss: 0.304266\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [15000/24999 (60%)]\tLoss: 0.307813\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [16000/24999 (64%)]\tLoss: 0.292261\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [17000/24999 (68%)]\tLoss: 0.294565\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [18000/24999 (72%)]\tLoss: 0.285286\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [19000/24999 (76%)]\tLoss: 0.290128\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [20000/24999 (80%)]\tLoss: 0.292967\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [21000/24999 (84%)]\tLoss: 0.291111\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [22000/24999 (88%)]\tLoss: 0.285600\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "Train Epoch: 2 [23000/24999 (92%)]\tLoss: 0.278948\n",
      "torch.Size([999, 25, 11, 11])\n",
      "Train Epoch: 2 [23976/24999 (96%)]\tLoss: 0.313944\n",
      "Train accuracy : 91.135645\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([1000, 25, 11, 11])\n",
      "torch.Size([811, 25, 11, 11])\n",
      "\n",
      "Test set: Average loss: 0.1549, Accuracy: 12212/12811 (95%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-01d5a796b5af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_instance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_instance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b1d6fc5b7e94>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, epoch)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.pyc\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m()\u001b[0m\n\u001b[0;32m    376\u001b[0m             \u001b[0mracquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[0mrrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/multiprocessing/queue.pyc\u001b[0m in \u001b[0;36mrecv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-191:\n",
      "Process Process-189:\n",
      "Process Process-192:\n",
      "Process Process-190:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "  File \"/home/vijay/cs231n/env/local/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 40, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"dataset.py\", line 25, in __getitem__\n",
      "  File \"dataset.py\", line 25, in __getitem__\n",
      "  File \"dataset.py\", line 25, in __getitem__\n",
      "  File \"dataset.py\", line 25, in __getitem__\n"
     ]
    }
   ],
   "source": [
    "# 95 % validation accuracy \n",
    "for epoch in range(1, 10):\n",
    "    train(model_instance, epoch)\n",
    "    test(model_instance)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(model_instance, './saved_models/net_c100xc25xf3025xf100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
